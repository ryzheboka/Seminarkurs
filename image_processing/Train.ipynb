{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(234, 288, 352, 3)\n",
      "(234, 8)\n"
     ]
    }
   ],
   "source": [
    "# Note: data isn't in the repository\n",
    "\n",
    "# loading data\n",
    "data = np.load(\"data/x_images.npy\")\n",
    "labels = np.load(\"data/y_images.npy\")\n",
    "\n",
    "# shuffling data\n",
    "indices = np.random.choice(np.arange(len(data)), size=len(data), replace=False)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "# encode labels to one-hot\n",
    "num_classes = len(set((labels)))\n",
    "labels = keras.utils.to_categorical(labels, num_classes)\n",
    "\n",
    "print(data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a pretrained model (without the top dense layers)\n",
    "\n",
    "base_model = keras.applications.xception.Xception(include_top=False, weights='imagenet', input_tensor=None, input_shape=[288,352,3], pooling=None, classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the layers except the last 2 layers, so the weights do not change\n",
    "# (number of layers can vary)\n",
    "for layer in base_model.layers[:-2]:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add layers to the pretrained network\n",
    "model = keras.Sequential()\n",
    "model.add(base_model)\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dropout(0.7))\n",
    "model.add(keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.6))\n",
    "model.add(keras.layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 163 samples, validate on 71 samples\n",
      "Epoch 1/100\n",
      "163/163 [==============================] - 10s 59ms/step - loss: 3.0989 - acc: 0.1104 - val_loss: 11.2054 - val_acc: 0.1549\n",
      "Epoch 2/100\n",
      "163/163 [==============================] - 2s 10ms/step - loss: 3.0845 - acc: 0.0982 - val_loss: 11.2254 - val_acc: 0.1408\n",
      "Epoch 3/100\n",
      "163/163 [==============================] - 2s 10ms/step - loss: 3.0763 - acc: 0.0859 - val_loss: 11.2262 - val_acc: 0.1408\n",
      "Epoch 4/100\n",
      "163/163 [==============================] - 2s 10ms/step - loss: 3.2891 - acc: 0.0859 - val_loss: 11.2269 - val_acc: 0.1408\n",
      "Epoch 5/100\n",
      "163/163 [==============================] - 2s 10ms/step - loss: 3.0315 - acc: 0.1288 - val_loss: 11.2201 - val_acc: 0.1408\n",
      "Epoch 6/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.9659 - acc: 0.0798 - val_loss: 11.2209 - val_acc: 0.1549\n",
      "Epoch 7/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 3.0761 - acc: 0.0859 - val_loss: 11.2205 - val_acc: 0.1549\n",
      "Epoch 8/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 3.1538 - acc: 0.0859 - val_loss: 11.2168 - val_acc: 0.1408\n",
      "Epoch 9/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 3.2026 - acc: 0.0859 - val_loss: 11.2089 - val_acc: 0.1549\n",
      "Epoch 10/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.9990 - acc: 0.1043 - val_loss: 11.2048 - val_acc: 0.1549\n",
      "Epoch 11/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 3.2298 - acc: 0.1104 - val_loss: 11.2043 - val_acc: 0.1549\n",
      "Epoch 12/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 3.0148 - acc: 0.1227 - val_loss: 11.2010 - val_acc: 0.1549\n",
      "Epoch 13/100\n",
      "163/163 [==============================] - 2s 10ms/step - loss: 3.1756 - acc: 0.0675 - val_loss: 11.1939 - val_acc: 0.1549\n",
      "Epoch 14/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 3.0039 - acc: 0.1043 - val_loss: 11.1915 - val_acc: 0.1549\n",
      "Epoch 15/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 3.0311 - acc: 0.0920 - val_loss: 11.1901 - val_acc: 0.1549\n",
      "Epoch 16/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 3.0071 - acc: 0.1166 - val_loss: 11.1863 - val_acc: 0.1549\n",
      "Epoch 17/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 3.1022 - acc: 0.0920 - val_loss: 11.1844 - val_acc: 0.1549\n",
      "Epoch 18/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.8630 - acc: 0.1656 - val_loss: 11.1844 - val_acc: 0.1549\n",
      "Epoch 19/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 3.1093 - acc: 0.1227 - val_loss: 11.1850 - val_acc: 0.1549\n",
      "Epoch 20/100\n",
      "163/163 [==============================] - 2s 10ms/step - loss: 2.9613 - acc: 0.1227 - val_loss: 11.1832 - val_acc: 0.1549\n",
      "Epoch 21/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 3.1306 - acc: 0.1104 - val_loss: 11.1834 - val_acc: 0.1549\n",
      "Epoch 22/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 3.0618 - acc: 0.1166 - val_loss: 11.1842 - val_acc: 0.1549\n",
      "Epoch 23/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.9703 - acc: 0.1043 - val_loss: 11.1848 - val_acc: 0.1549\n",
      "Epoch 24/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 3.0732 - acc: 0.1166 - val_loss: 11.1844 - val_acc: 0.1549\n",
      "Epoch 25/100\n",
      "163/163 [==============================] - 2s 10ms/step - loss: 3.0553 - acc: 0.1104 - val_loss: 11.1842 - val_acc: 0.1549\n",
      "Epoch 26/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 3.0697 - acc: 0.1104 - val_loss: 11.1820 - val_acc: 0.1549\n",
      "Epoch 27/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.9260 - acc: 0.1288 - val_loss: 11.1840 - val_acc: 0.1549\n",
      "Epoch 28/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 3.1614 - acc: 0.1288 - val_loss: 11.1838 - val_acc: 0.1549\n",
      "Epoch 29/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 3.0057 - acc: 0.1043 - val_loss: 11.1828 - val_acc: 0.1549\n",
      "Epoch 30/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.9352 - acc: 0.1534 - val_loss: 11.1798 - val_acc: 0.1549\n",
      "Epoch 31/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 3.0065 - acc: 0.0982 - val_loss: 11.1740 - val_acc: 0.1549\n",
      "Epoch 32/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.9690 - acc: 0.1104 - val_loss: 11.1729 - val_acc: 0.1549\n",
      "Epoch 33/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 3.1327 - acc: 0.0920 - val_loss: 11.1727 - val_acc: 0.1549\n",
      "Epoch 34/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 3.0912 - acc: 0.1043 - val_loss: 11.1664 - val_acc: 0.1549\n",
      "Epoch 35/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.9240 - acc: 0.1166 - val_loss: 11.1655 - val_acc: 0.1549\n",
      "Epoch 36/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.8771 - acc: 0.1104 - val_loss: 11.1656 - val_acc: 0.1549\n",
      "Epoch 37/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 3.1859 - acc: 0.0920 - val_loss: 11.1646 - val_acc: 0.1549\n",
      "Epoch 38/100\n",
      "163/163 [==============================] - 2s 10ms/step - loss: 2.9444 - acc: 0.1104 - val_loss: 11.1653 - val_acc: 0.1549\n",
      "Epoch 39/100\n",
      "163/163 [==============================] - 2s 10ms/step - loss: 3.0129 - acc: 0.1043 - val_loss: 11.1660 - val_acc: 0.1549\n",
      "Epoch 40/100\n",
      "163/163 [==============================] - 2s 10ms/step - loss: 2.9775 - acc: 0.1227 - val_loss: 11.1633 - val_acc: 0.1549\n",
      "Epoch 41/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 3.1427 - acc: 0.0613 - val_loss: 11.1633 - val_acc: 0.1549\n",
      "Epoch 42/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 3.1997 - acc: 0.0982 - val_loss: 11.1603 - val_acc: 0.1549\n",
      "Epoch 43/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 3.1809 - acc: 0.0982 - val_loss: 11.1600 - val_acc: 0.1549\n",
      "Epoch 44/100\n",
      "163/163 [==============================] - 2s 10ms/step - loss: 3.0716 - acc: 0.1104 - val_loss: 11.1569 - val_acc: 0.1549\n",
      "Epoch 45/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 3.0226 - acc: 0.1227 - val_loss: 11.1570 - val_acc: 0.1549\n",
      "Epoch 46/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 3.0589 - acc: 0.0982 - val_loss: 11.1559 - val_acc: 0.1549\n",
      "Epoch 47/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.8543 - acc: 0.1227 - val_loss: 11.1549 - val_acc: 0.1549\n",
      "Epoch 48/100\n",
      "163/163 [==============================] - 2s 10ms/step - loss: 3.0710 - acc: 0.0982 - val_loss: 11.1516 - val_acc: 0.1549\n",
      "Epoch 49/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 3.0483 - acc: 0.1227 - val_loss: 11.1499 - val_acc: 0.1549\n",
      "Epoch 50/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.8021 - acc: 0.1227 - val_loss: 11.1499 - val_acc: 0.1549\n",
      "Epoch 51/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.9524 - acc: 0.1043 - val_loss: 11.1484 - val_acc: 0.1549\n",
      "Epoch 52/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.8604 - acc: 0.1166 - val_loss: 11.1451 - val_acc: 0.1549\n",
      "Epoch 53/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.8870 - acc: 0.1227 - val_loss: 11.1434 - val_acc: 0.1549\n",
      "Epoch 54/100\n",
      "163/163 [==============================] - 2s 10ms/step - loss: 3.1022 - acc: 0.0552 - val_loss: 11.1436 - val_acc: 0.1549\n",
      "Epoch 55/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 3.0156 - acc: 0.0920 - val_loss: 11.1420 - val_acc: 0.1549\n",
      "Epoch 56/100\n",
      "163/163 [==============================] - 2s 10ms/step - loss: 3.0576 - acc: 0.1104 - val_loss: 11.1425 - val_acc: 0.1549\n",
      "Epoch 57/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.8855 - acc: 0.0920 - val_loss: 11.1429 - val_acc: 0.1549\n",
      "Epoch 58/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.9804 - acc: 0.1104 - val_loss: 11.1417 - val_acc: 0.1549\n",
      "Epoch 59/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.7723 - acc: 0.1595 - val_loss: 11.1406 - val_acc: 0.1549\n",
      "Epoch 60/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.9725 - acc: 0.1104 - val_loss: 11.1404 - val_acc: 0.1549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "163/163 [==============================] - 2s 10ms/step - loss: 3.0392 - acc: 0.1288 - val_loss: 11.1389 - val_acc: 0.1549\n",
      "Epoch 62/100\n",
      "163/163 [==============================] - 2s 10ms/step - loss: 2.7727 - acc: 0.1718 - val_loss: 11.1381 - val_acc: 0.1549\n",
      "Epoch 63/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.8547 - acc: 0.1043 - val_loss: 11.1359 - val_acc: 0.1549\n",
      "Epoch 64/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.9231 - acc: 0.1350 - val_loss: 11.1350 - val_acc: 0.1549\n",
      "Epoch 65/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 3.1155 - acc: 0.1043 - val_loss: 11.1351 - val_acc: 0.1549\n",
      "Epoch 66/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 3.0584 - acc: 0.1104 - val_loss: 11.1348 - val_acc: 0.1549\n",
      "Epoch 67/100\n",
      "163/163 [==============================] - 2s 10ms/step - loss: 2.8267 - acc: 0.1104 - val_loss: 11.1354 - val_acc: 0.1549\n",
      "Epoch 68/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.7756 - acc: 0.1718 - val_loss: 11.1332 - val_acc: 0.1549\n",
      "Epoch 69/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.9688 - acc: 0.1288 - val_loss: 11.1315 - val_acc: 0.1549\n",
      "Epoch 70/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 3.0767 - acc: 0.0552 - val_loss: 11.1286 - val_acc: 0.1549\n",
      "Epoch 71/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.9735 - acc: 0.1227 - val_loss: 11.1294 - val_acc: 0.1549\n",
      "Epoch 72/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.8257 - acc: 0.1411 - val_loss: 11.1272 - val_acc: 0.1549\n",
      "Epoch 73/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 3.1075 - acc: 0.0859 - val_loss: 11.1268 - val_acc: 0.1549\n",
      "Epoch 74/100\n",
      "163/163 [==============================] - 2s 10ms/step - loss: 2.9772 - acc: 0.1288 - val_loss: 11.1240 - val_acc: 0.1549\n",
      "Epoch 75/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.9722 - acc: 0.1166 - val_loss: 11.1187 - val_acc: 0.1549\n",
      "Epoch 76/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 3.0538 - acc: 0.1227 - val_loss: 11.1180 - val_acc: 0.1549\n",
      "Epoch 77/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.8349 - acc: 0.0982 - val_loss: 11.1141 - val_acc: 0.1549\n",
      "Epoch 78/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.8891 - acc: 0.0920 - val_loss: 11.1123 - val_acc: 0.1549\n",
      "Epoch 79/100\n",
      "163/163 [==============================] - 2s 10ms/step - loss: 2.8866 - acc: 0.1227 - val_loss: 11.1083 - val_acc: 0.1549\n",
      "Epoch 80/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.9485 - acc: 0.1043 - val_loss: 11.1089 - val_acc: 0.1549\n",
      "Epoch 81/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.8114 - acc: 0.1288 - val_loss: 11.1095 - val_acc: 0.1549\n",
      "Epoch 82/100\n",
      "163/163 [==============================] - 2s 10ms/step - loss: 2.9392 - acc: 0.0982 - val_loss: 11.1047 - val_acc: 0.1549\n",
      "Epoch 83/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.8313 - acc: 0.1288 - val_loss: 11.1048 - val_acc: 0.1549\n",
      "Epoch 84/100\n",
      "163/163 [==============================] - 2s 10ms/step - loss: 2.6327 - acc: 0.1227 - val_loss: 11.1051 - val_acc: 0.1549\n",
      "Epoch 85/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 3.1041 - acc: 0.1472 - val_loss: 11.1035 - val_acc: 0.1549\n",
      "Epoch 86/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.7855 - acc: 0.1166 - val_loss: 11.1031 - val_acc: 0.1549\n",
      "Epoch 87/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.9328 - acc: 0.0920 - val_loss: 11.1027 - val_acc: 0.1549\n",
      "Epoch 88/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.8943 - acc: 0.1166 - val_loss: 11.1029 - val_acc: 0.1549\n",
      "Epoch 89/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.8236 - acc: 0.1104 - val_loss: 11.1008 - val_acc: 0.1549\n",
      "Epoch 90/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.8564 - acc: 0.1411 - val_loss: 11.0997 - val_acc: 0.1549\n",
      "Epoch 91/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.8456 - acc: 0.0859 - val_loss: 11.0979 - val_acc: 0.1549\n",
      "Epoch 92/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.9394 - acc: 0.1043 - val_loss: 11.0962 - val_acc: 0.1549\n",
      "Epoch 93/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.7918 - acc: 0.1350 - val_loss: 11.0960 - val_acc: 0.1549\n",
      "Epoch 94/100\n",
      "163/163 [==============================] - 2s 10ms/step - loss: 3.0149 - acc: 0.0859 - val_loss: 11.0948 - val_acc: 0.1549\n",
      "Epoch 95/100\n",
      "163/163 [==============================] - 2s 10ms/step - loss: 2.9109 - acc: 0.1227 - val_loss: 11.0938 - val_acc: 0.1549\n",
      "Epoch 96/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.9554 - acc: 0.1472 - val_loss: 11.0940 - val_acc: 0.1549\n",
      "Epoch 97/100\n",
      "163/163 [==============================] - 2s 10ms/step - loss: 2.9760 - acc: 0.0859 - val_loss: 11.0904 - val_acc: 0.1549\n",
      "Epoch 98/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 3.0406 - acc: 0.1043 - val_loss: 11.0909 - val_acc: 0.1549\n",
      "Epoch 99/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.7628 - acc: 0.1350 - val_loss: 11.0905 - val_acc: 0.1549\n",
      "Epoch 100/100\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 2.9389 - acc: 0.1350 - val_loss: 11.0902 - val_acc: 0.1549\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(lr=1e-8),\n",
    "              metrics=['acc'])\n",
    "# Train the model\n",
    "history = model.fit(x=data,y=labels,batch_size=50,epochs=100,validation_split=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "val_acc = str(int(history.history[\"val_acc\"][-1]*100))\n",
    "val_loss = str(int(history.history[\"val_loss\"][-1]*10))\n",
    "filename = 'data/model/model_val_acc_'+val_acc+\"_val_loss_\"+val_loss+'.h5'\n",
    "model.save(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
